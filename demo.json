[
	{
		"media" : "media/intro.jpg",
		"text" : "Welcome to our demonstration, showcasing the advancements achieved by Work Package 5 in the ADMIRE Euro-HPC project. This segment focuses on monitoring, modeling, and profiling. Before we proceed, let's revisit the challenges that have driven our innovation and development."
	},
	{
		"media" : "media/WP5_DEMO_MOLDABILITY.m4v",
		"text" : "When running a program across multiple nodes, resource utilization can vary. GPUs and IOs are not always fully utilized. In a Multi-Program Multiple Data scenario, this underutilization leads to wasted resources. The ADMIRE project aims to identify these inefficiencies, enabling the use of malleable payloads. Malleable payloads dynamically reshape themselves over time, like the yellow boxes in our example. This approach coordinates jobs and shares system resources, enhancing overall efficiency while remaining transparent."
	},
	{
		"media" : "media/space_time.m4v",
		"text" : "When monitoring a parallel program running on a supercomputer, the volume of collected metrics is crucial. We don't just monitor the system as a whole; we also track its performance over time. This results in a combinatorial explosion of performance data that needs to be managed. To address this challenge, we have designed and implemented highly scalable approaches to maintain the temporal perspective necessary for making informed malleability decisions."
	},
	{
		"media" : "media/WP5_DEMO_JOB_LEVEL.m4v",
		"text" : "In addition, when examining the machine state more closely, each node must be considered individually, with slots (or more practically, cores) serving as the allocation units recognized by the batch manager, also referred to as the number of processes. Therefore, in conjunction with space and time, we must also meticulously monitor individual jobs running across the entire system. This comprehensive monitoring enables the central component of the ADMIRE system, the intelligent controller, to make well-informed decisions."
	},
	{
		"media" : "media/WP5_DEMO_PROXY_ARCH.m4v",
		"text" : "At the center of our monitoring infrastructure is the metric proxy. This essential tool collects metrics and forwards them in a scalable manner, effectively monitoring distributed jobs as they come and go. The metric proxy can consume data from existing Prometheus exporters and is responsible for monitoring the state of each node. The proxy is capable of forwarding these data to various consumers. First, it can send data to a Prometheus instance. Second, it can forward trace data, capturing detailed execution flows. Additionally, the proxy can generate profiles that abstract the temporal dimension, which are then used to create scalability performance models."
	},
	{
		"media" : "media/WP5_DEMO_PROXY_TBON.m4v",
		"text" : "To meet the measurement needs of the proxy, we utilized the limitless tree-based overlay network infrastructure. This innovative solution allows data to be reduced over space, facilitating high-frequency monitoring of a large number of machines in a scalable manner. Thanks to this infrastructure, we can dynamically obtain the current state of jobs while reducing hundreds of metrics every second. This enables a comprehensive global view of the system without sacrificing detailed per-node insights. At the root level, these data are stored in per-job and per-node traces, as well as profiles for each job. Additionally, the proxy can act as a model server, ensuring efficient data handling and analysis across the entire monitoring infrastructure."
	},
	{
		"media" : "media/profiles.ogv",
		"text" : "The proxy features an interactive HTML interface, enabling users to monitor its state effectively. Proxies are organized in a tree-based overlay network, reducing data toward a root proxy that performs the final data storage. This setup allows for real-time job monitoring. For instance, when we launch a benchmark job, we can observe the counters updating nearly in real time, providing immediate insights into system performance and job status."
	},
	{
		"media" : "media/profview.ogv",
		"text" : "The final state of each job, called a profile, is stored and gathered through command lines. This enables monitoring and comparison of executions while generating models. This process creates an extensive catalog of previous executions for a given program across various scales and configurations. Later, we will demonstrate how Extra-P can be used to create models from this data, further enhancing our understanding and optimization of job performance."
	},
	{
		"media" : "media/trace.ogv",
		"text" : "In complement, real-time profiling data are aggregated into traces. These traces are of limited size and are resampled on the fly, prioritizing storage efficiency over temporal resolution. By examining the current job, we can access historical data for various metrics, allowing us to observe trends and changes over time. The proxy can also derive data over time to compute bandwidth. Additionally, past jobs are stored in binary traces, providing a rich dataset for analysis. This comprehensive collection of data supports the malleability decisions made by the intelligent controller, ensuring optimal resource allocation and system performance."
	},
	{
		"media" : "media/WP5_DEMO_PROXY_MODEL.m4v",
		"text" : "Performance modeling is a crucial aspect of the metric proxy, as it provides the intelligent controller with valorized data, enabling quick and informed decisions while avoiding data deluge. The proxy constantly valorizes performance data through two key methods: Extra-P: This tool allows scalability predictions by analyzing previous executions of a given program at various scales. By leveraging Extra-P, the intelligent controller can predict metrics at unknown scales, practically supporting malleability and optimizing resource allocation. FT-IO: This innovative tool, developed within ADMIRE, performs performance analysis in the frequency domain. FT-IO creates compact temporal descriptors for periodic signals, enabling behavioral prediction over the temporal axis, including bursts and contention. Thus, the proxy also functions as a model gateway, with interfaces (HTTP REST and Mercury) to support the intelligent controller's decisions. This approach prevents the forwarding of raw performance data, which can be challenging to consume and interpret at scale, thereby streamlining the decision-making process and enhancing overall system efficiency."
	},
	{
		"media" : "media/model.ogv",
		"text" : "In this example, we can see the HTML interface of the model server for Extra-P scalability models. Each job is associated with a transversal model representing its scalability and is grouped by command-line. The interface allows not only the retrieval of these models but also enables performance projection using the regression models, similar to the Extra-P interface. This always-on modeling process within the proxy is a key element in the ADMIRE malleability decision-making process. By providing continuous scalability projections and performance insights, it ensures that the intelligent controller can make informed, efficient, and adaptive resource management decisions."
	},
	{
		"media" : "media/oss.jpg",
		"text" : "All tools developed by Work Package 5 are available in the ADMIRE GitHub repository as open-source software. This collaborative initiative provides a robust set of tools that will be maintained by the various project partners, ensuring ongoing improvements and support. By making these tools publicly accessible, we aim to foster a collaborative environment that enhances the capabilities and efficiency of supercomputing resources."
	}



]
